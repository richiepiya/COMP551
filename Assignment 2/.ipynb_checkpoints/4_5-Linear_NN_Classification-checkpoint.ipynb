{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Read data from DataSets\n",
    "mean1_pos = pd.read_csv(\"data/DS2_c1_m1.txt\", header=None)\n",
    "mean2_pos = pd.read_csv(\"data/DS2_c1_m2.txt\", header=None)\n",
    "mean3_pos = pd.read_csv(\"data/DS2_c1_m3.txt\", header=None)\n",
    "mean1_neg = pd.read_csv(\"data/DS2_c2_m1.txt\", header=None)\n",
    "mean2_neg = pd.read_csv(\"data/DS2_c2_m2.txt\", header=None)\n",
    "mean3_neg = pd.read_csv(\"data/DS2_c2_m3.txt\", header=None)\n",
    "cov1 = pd.read_csv(\"data/DS2_Cov1.txt\", header=None)\n",
    "cov2 = pd.read_csv(\"data/DS2_Cov2.txt\", header=None)\n",
    "cov3 = pd.read_csv(\"data/DS2_Cov3.txt\", header=None)\n",
    "# Drop end column (not useful to us)\n",
    "mean1_pos.drop([20], axis=1, inplace=True)\n",
    "mean2_pos.drop([20], axis=1, inplace=True)\n",
    "mean3_pos.drop([20], axis=1, inplace=True)\n",
    "mean1_neg.drop([20], axis=1, inplace=True)\n",
    "mean2_neg.drop([20], axis=1, inplace=True)\n",
    "mean3_neg.drop([20], axis=1, inplace=True)\n",
    "cov1.drop([20], axis=1, inplace=True)\n",
    "cov2.drop([20], axis=1, inplace=True)\n",
    "cov3.drop([20], axis=1, inplace=True)\n",
    "# Change to matrices\n",
    "mean1_pos_m = mean1_pos.as_matrix()[0]\n",
    "mean2_pos_m = mean2_pos.as_matrix()[0]\n",
    "mean3_pos_m = mean3_pos.as_matrix()[0]\n",
    "mean1_neg_m = mean1_neg.as_matrix()[0]\n",
    "mean2_neg_m = mean2_neg.as_matrix()[0]\n",
    "mean3_neg_m = mean3_neg.as_matrix()[0]\n",
    "cov1_m = cov1.as_matrix()[0]\n",
    "cov2_m = cov2.as_matrix()[0]\n",
    "cov3_m = cov3.as_matrix()[0]\n",
    "\n",
    "# Generate 2000 examples for each class\n",
    "dataEx = 2000\n",
    "class1_neg = pd.DataFrame(np.random.multivariate_normal(mean1_neg_m, cov1, dataEx))\n",
    "class2_neg = pd.DataFrame(np.random.multivariate_normal(mean2_neg_m, cov2, dataEx))\n",
    "class3_neg = pd.DataFrame(np.random.multivariate_normal(mean3_neg_m, cov3, dataEx))\n",
    "class1_pos = pd.DataFrame(np.random.multivariate_normal(mean1_pos_m, cov1, dataEx))\n",
    "class2_pos = pd.DataFrame(np.random.multivariate_normal(mean2_pos_m, cov2, dataEx))\n",
    "class3_pos = pd.DataFrame(np.random.multivariate_normal(mean3_pos_m, cov3, dataEx))\n",
    "# Add classification column and convert to matrix\n",
    "class1_neg[20] = 0\n",
    "class2_neg[20] = 0\n",
    "class3_neg[20] = 0\n",
    "class1_pos[20] = 1\n",
    "class2_pos[20] = 1\n",
    "class3_pos[20] = 1\n",
    "class1_neg_m = class1_neg.as_matrix()\n",
    "class2_neg_m = class2_neg.as_matrix()\n",
    "class3_neg_m = class3_neg.as_matrix()\n",
    "class1_pos_m = class1_pos.as_matrix()\n",
    "class2_pos_m = class2_pos.as_matrix()\n",
    "class3_pos_m = class3_pos.as_matrix()\n",
    "\n",
    "# Split data into train, valid, test sets\n",
    "allData1 = np.concatenate((class1_neg_m, class1_pos_m), axis=0)\n",
    "allData2 = np.concatenate((class2_neg_m, class2_pos_m), axis=0)\n",
    "allData3 = np.concatenate((class3_neg_m, class3_pos_m), axis=0)\n",
    "np.random.shuffle(allData1)\n",
    "np.random.shuffle(allData2)\n",
    "np.random.shuffle(allData3)\n",
    "trainSet1 = pd.DataFrame(allData1[0:2400])\n",
    "trainSet2 = pd.DataFrame(allData2[0:2400])\n",
    "trainSet3 = pd.DataFrame(allData3[0:2400])\n",
    "validSet1 = pd.DataFrame(allData1[2400:3200])\n",
    "validSet2 = pd.DataFrame(allData2[2400:3200])\n",
    "validSet3 = pd.DataFrame(allData3[2400:3200])\n",
    "testSet1 = pd.DataFrame(allData1[3200:4000])\n",
    "testSet2 = pd.DataFrame(allData2[3200:4000])\n",
    "testSet3 = pd.DataFrame(allData3[3200:4000])\n",
    "# Concatenate data from the 3 Gaussian datasets\n",
    "allData = np.concatenate((pd.DataFrame(allData1), pd.DataFrame(allData2), pd.DataFrame(allData3)), axis=0)\n",
    "trainSet = pd.DataFrame(np.concatenate((trainSet1, trainSet2, trainSet3), axis=0))\n",
    "validSet = pd.DataFrame(np.concatenate((validSet1, validSet2, validSet3), axis=0))\n",
    "testSet = pd.DataFrame(np.concatenate((testSet1, testSet2, testSet3), axis=0))\n",
    "\n",
    "### 4. Save completed datasets ###\n",
    "pd.DataFrame(allData).to_csv(\"dataGenerated/DS2_data.csv\", index=False, header=False)\n",
    "trainSet.to_csv(\"dataGenerated/DS2_train.csv\", index=False, header=False)\n",
    "validSet.to_csv(\"dataGenerated/DS2_valid.csv\", index=False, header=False)\n",
    "testSet.to_csv(\"dataGenerated/DS2_test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:  [[ 7.56169367  5.64754268  5.03943775  5.13906646  4.55223492  6.07501614\n",
      "   5.61651127  5.47711743  4.78996973  5.50180405  5.43352109  5.2442264\n",
      "   5.48374432  6.17417384  5.48216603  5.84502266  5.612228    5.29520831\n",
      "   5.34138188  5.85475509]\n",
      " [ 5.64754268  7.70816138  5.53592544  5.50191941  5.44724338  6.7257495\n",
      "   6.40898454  5.76894248  5.08351081  5.65267822  5.27305654  5.69888356\n",
      "   5.48083503  6.39271987  5.98635782  6.30688827  5.98772765  5.34417968\n",
      "   6.13117252  6.20283434]\n",
      " [ 5.03943775  5.53592544  6.99794496  5.2872627   5.15774254  5.65569679\n",
      "   5.92321446  4.88120725  5.03845943  5.27570563  5.01667934  5.29912099\n",
      "   5.51262949  6.21791229  5.33952636  5.27536418  5.70613317  4.70000908\n",
      "   5.68174748  6.03514885]\n",
      " [ 5.13906646  5.50191941  5.2872627   6.60019364  4.4256281   5.85194092\n",
      "   5.742914    5.54676071  4.92313805  5.59054672  4.96471657  5.28627163\n",
      "   5.1257205   5.52809292  5.46387196  5.40322586  5.42758112  5.17622819\n",
      "   5.64739102  5.81131098]\n",
      " [ 4.55223492  5.44724338  5.15774254  4.4256281   5.99020913  5.34190869\n",
      "   5.07970844  4.82245888  4.07542057  4.50784621  3.99479147  4.39840986\n",
      "   4.80439317  5.19755184  5.24898353  5.20639321  5.08143242  4.76282282\n",
      "   5.18468137  5.37015591]\n",
      " [ 6.07501614  6.7257495   5.65569679  5.85194092  5.34190869  8.76439859\n",
      "   6.77562793  5.67914929  5.97704561  6.18441191  5.27783696  5.79645127\n",
      "   6.48518375  6.85568976  6.21033081  6.59270291  6.38195503  6.05748531\n",
      "   6.67703267  6.77042424]\n",
      " [ 5.61651127  6.40898454  5.92321446  5.742914    5.07970844  6.77562793\n",
      "   7.78763795  5.89226445  5.51197417  6.08768767  5.59978125  5.70846091\n",
      "   5.63772466  6.56786956  5.81875993  6.11736517  5.84980038  5.56900774\n",
      "   6.45957232  6.31474406]\n",
      " [ 5.47711743  5.76894248  4.88120725  5.54676071  4.82245888  5.67914929\n",
      "   5.89226445  6.67385427  4.75307741  5.42614278  4.78009346  5.13477609\n",
      "   4.68137132  5.63465777  5.56983281  5.5571474   5.32378635  5.66317601\n",
      "   5.46361794  5.84971606]\n",
      " [ 4.78996973  5.08351081  5.03845943  4.92313805  4.07542057  5.97704561\n",
      "   5.51197417  4.75307741  6.16219934  4.85971555  4.55926322  4.72652902\n",
      "   4.93028947  5.07108922  4.90985816  4.6465551   5.1070059   4.6220709\n",
      "   5.01257346  5.24966538]\n",
      " [ 5.50180405  5.65267822  5.27570563  5.59054672  4.50784621  6.18441191\n",
      "   6.08768767  5.42614278  4.85971555  7.08614168  4.99879845  5.10898413\n",
      "   5.3472592   5.95926306  5.49925897  5.41816955  5.39186821  4.86618031\n",
      "   5.95949876  5.74413029]\n",
      " [ 5.43352109  5.27305654  5.01667934  4.96471657  3.99479147  5.27783696\n",
      "   5.59978125  4.78009346  4.55926322  4.99879845  6.12582482  5.22935824\n",
      "   5.01699515  5.35821922  5.19212868  4.98026235  4.89709215  4.74006103\n",
      "   5.3937733   5.47221548]\n",
      " [ 5.2442264   5.69888356  5.29912099  5.28627163  4.39840986  5.79645127\n",
      "   5.70846091  5.13477609  4.72652902  5.10898413  5.22935824  6.96215749\n",
      "   5.05795261  5.6562435   5.79446213  5.44558868  5.66383584  5.29707915\n",
      "   5.47680518  5.85380017]\n",
      " [ 5.48374432  5.48083503  5.51262949  5.1257205   4.80439317  6.48518375\n",
      "   5.63772466  4.68137132  4.93028947  5.3472592   5.01699515  5.05795261\n",
      "   7.01645747  5.94746216  5.89203683  5.7892457   5.65103163  5.06213856\n",
      "   5.81051347  5.81676952]\n",
      " [ 6.17417384  6.39271987  6.21791229  5.52809292  5.19755184  6.85568976\n",
      "   6.56786956  5.63465777  5.07108922  5.95926306  5.35821922  5.6562435\n",
      "   5.94746216  8.12812836  5.98288125  6.18552667  6.2800869   5.08700343\n",
      "   6.11296913  6.40472631]\n",
      " [ 5.48216603  5.98635782  5.33952636  5.46387196  5.24898353  6.21033081\n",
      "   5.81875993  5.56983281  4.90985816  5.49925897  5.19212868  5.79446213\n",
      "   5.89203683  5.98288125  7.36333934  5.70526899  5.80283173  5.44133813\n",
      "   5.69064553  6.40259339]\n",
      " [ 5.84502266  6.30688827  5.27536418  5.40322586  5.20639321  6.59270291\n",
      "   6.11736517  5.5571474   4.6465551   5.41816955  4.98026235  5.44558868\n",
      "   5.7892457   6.18552667  5.70526899  7.13474242  5.77889258  5.84702016\n",
      "   6.03795402  5.99102181]\n",
      " [ 5.612228    5.98772765  5.70613317  5.42758112  5.08143242  6.38195503\n",
      "   5.84980038  5.32378635  5.1070059   5.39186821  4.89709215  5.66383584\n",
      "   5.65103163  6.2800869   5.80283173  5.77889258  7.39843704  5.02848434\n",
      "   5.75388477  6.38780367]\n",
      " [ 5.29520831  5.34417968  4.70000908  5.17622819  4.76282282  6.05748531\n",
      "   5.56900774  5.66317601  4.6220709   4.86618031  4.74006103  5.29707915\n",
      "   5.06213856  5.08700343  5.44133813  5.84702016  5.02848434  6.94624416\n",
      "   5.53899221  5.7667674 ]\n",
      " [ 5.34138188  6.13117252  5.68174748  5.64739102  5.18468137  6.67703267\n",
      "   6.45957232  5.46361794  5.01257346  5.95949876  5.3937733   5.47680518\n",
      "   5.81051347  6.11296913  5.69064553  6.03795402  5.75388477  5.53899221\n",
      "   7.74146587  6.29538934]\n",
      " [ 5.85475509  6.20283434  6.03514885  5.81131098  5.37015591  6.77042424\n",
      "   6.31474406  5.84971606  5.24966538  5.74413029  5.47221548  5.85380017\n",
      "   5.81676952  6.40472631  6.40259339  5.99102181  6.38780367  5.7667674\n",
      "   6.29538934  8.20530814]] \n",
      "\n",
      "w0:  -0.147775446626\n",
      "w1:  [-0.00629905 -0.04532273 -0.0781147   0.05489176  0.11819182 -0.02588029\n",
      " -0.05579255 -0.01832064  0.06520449  0.03776821  0.07484969  0.04302516\n",
      "  0.0017316   0.01996336 -0.02421451  0.01356156  0.01791875 -0.0222463\n",
      "  0.0027015  -0.04252262] \n",
      "\n",
      "Confusion Matrix:  [[660, 524], [573, 643]] \n",
      "\n",
      "Accuracy:  0.5429166666666667\n",
      "Precision:  0.5574324324324325\n",
      "Recall:  0.5352798053527981\n",
      "F-measure:  0.546131568059578\n"
     ]
    }
   ],
   "source": [
    "### 5.1 GDA Approach ###\n",
    "\n",
    "# Split training data\n",
    "trainSet0 = trainSet[trainSet[20] == 0]\n",
    "trainSet1 = trainSet[trainSet[20] == 1]\n",
    "testOut = testSet[20]\n",
    "# Drop end column\n",
    "trainSet0.drop([20], axis=1, inplace=True)\n",
    "trainSet1.drop([20], axis=1, inplace=True)\n",
    "trainSet.drop([20], axis=1, inplace=True)\n",
    "testSet.drop([20], axis=1, inplace=True)\n",
    "\n",
    "# Get length of each training set\n",
    "numData0 = len(trainSet0)\n",
    "numData1 = len(trainSet1)\n",
    "# Create nd.array versions of data sets\n",
    "trainSet_arr = trainSet.as_matrix()\n",
    "testSet_arr = testSet.as_matrix()\n",
    "\n",
    "# Get probability of each training set\n",
    "allDataPts = numData0 + numData1\n",
    "prob0 = numData0 / allDataPts\n",
    "prob1 = numData1 / allDataPts\n",
    "\n",
    "# Get mean of each column\n",
    "mean0 = np.array(trainSet0.mean())\n",
    "mean1 = np.array(trainSet1.mean())\n",
    "\n",
    "# Compute covariance matrices to get w0 & w1\n",
    "cov0 = np.array(trainSet0-mean0)\n",
    "cov1 = np.array(trainSet1-mean1)\n",
    "s0 = np.matmul(cov0.T, cov0)\n",
    "s1 = np.matmul(cov1.T, cov1)\n",
    "cov = (s0 + s1) / allDataPts\n",
    "cov_inv = np.linalg.inv(cov)\n",
    "w0 = (math.log(prob0)-math.log(prob1)) - (np.matmul(np.matmul(mean0.T, cov_inv), mean0) - np.matmul(np.matmul(mean1.T, cov_inv), mean1))/2\n",
    "w1 = np.matmul(cov_inv, (mean0 - mean1))\n",
    "print(\"Covariance matrix: \", cov, \"\\n\")\n",
    "print(\"w0: \", w0)\n",
    "print(\"w1: \", w1, \"\\n\")\n",
    "\n",
    "# Compute GDA model\n",
    "outPredict = np.matmul(testSet, w1.T) + w0\n",
    "sigmoid = np.exp(outPredict) / (np.exp(outPredict) + 1)\n",
    "for i in range(len(sigmoid)):\n",
    "    if (sigmoid[i] > 0.5):\n",
    "        sigmoid[i] = 0\n",
    "    else:\n",
    "        sigmoid[i] = 1\n",
    "        \n",
    "# Compute confusion matrix values\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for j in range(len(testOut)):\n",
    "    predVal = sigmoid[j]\n",
    "    actualVal = testOut[j]\n",
    "\n",
    "    # Compare actual to predicted values\n",
    "    if (predVal == 1 and predVal == actualVal):\n",
    "        tp += 1\n",
    "    elif (predVal == 1 and predVal != actualVal):\n",
    "        fp += 1\n",
    "    elif (predVal == 0 and predVal == actualVal):\n",
    "        tn += 1\n",
    "    elif (predVal == 0 and predVal != actualVal):\n",
    "        fn += 1\n",
    "        \n",
    "# Create confusion matrix\n",
    "confMatrix = [[0, 0], [0, 0]]\n",
    "confMatrix[0][0] = tp\n",
    "confMatrix[0][1] = fp\n",
    "confMatrix[1][0] = fn\n",
    "confMatrix[1][1] = tn\n",
    "        \n",
    "# Compute results\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f_measure = (2 * (precision * recall)) / (precision + recall)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix: \", confMatrix, \"\\n\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F-measure: \", f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Accuracy: 0.47041666666666665\n",
      "k: 2, Accuracy: 0.465\n",
      "k: 3, Accuracy: 0.4683333333333333\n",
      "k: 4, Accuracy: 0.46875\n",
      "k: 5, Accuracy: 0.4708333333333333\n",
      "k: 6, Accuracy: 0.46958333333333335\n",
      "k: 7, Accuracy: 0.4708333333333333\n",
      "k: 8, Accuracy: 0.47291666666666665\n",
      "k: 9, Accuracy: 0.47541666666666665\n",
      "k: 10, Accuracy: 0.47\n",
      "k: 11, Accuracy: 0.4691666666666667\n",
      "k: 12, Accuracy: 0.47041666666666665\n",
      "k: 13, Accuracy: 0.4716666666666667\n",
      "k: 14, Accuracy: 0.46875\n",
      "k: 15, Accuracy: 0.47\n",
      "k: 16, Accuracy: 0.47208333333333335\n",
      "k: 17, Accuracy: 0.46875\n",
      "k: 18, Accuracy: 0.47041666666666665\n",
      "k: 19, Accuracy: 0.47041666666666665\n",
      "k: 20, Accuracy: 0.4683333333333333\n",
      "k: 21, Accuracy: 0.47041666666666665\n",
      "k: 22, Accuracy: 0.4683333333333333\n",
      "k: 23, Accuracy: 0.46875\n",
      "k: 24, Accuracy: 0.46625\n",
      "k: 25, Accuracy: 0.46708333333333335\n",
      "k: 26, Accuracy: 0.46541666666666665\n",
      "k: 27, Accuracy: 0.4666666666666667\n",
      "k: 28, Accuracy: 0.46541666666666665\n",
      "k: 29, Accuracy: 0.465\n",
      "k: 30, Accuracy: 0.46791666666666665\n",
      "\n",
      "Optimal k value:  9\n",
      "Confusion Matrix:  [[781, 807], [452, 360]] \n",
      "\n",
      "Accuracy:  0.47541666666666665\n",
      "Precision:  0.49181360201511337\n",
      "Recall:  0.6334144363341444\n",
      "F-measure:  0.553704360155973\n"
     ]
    }
   ],
   "source": [
    "### 5.2 k-NN Approach ###\n",
    "\n",
    "# Store optimal values\n",
    "k_opt = 0\n",
    "confMatrix_opt = [[0, 0], [0, 0]]\n",
    "accuracy_opt = 0.0\n",
    "\n",
    "# Compute k-NN up to k=30\n",
    "for k in range(1, 31):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(testOut)):\n",
    "        x = trainSet_arr\n",
    "        y_i = testSet_arr[i]\n",
    "        \n",
    "        # Compute and sort distances\n",
    "        distances = np.power(np.linalg.norm(x - y_i, axis=1), 2)\n",
    "        neighbours = distances.argsort()[:k]\n",
    "        if (trainSet_arr[neighbours, 19].sum() > 0):\n",
    "            predVal = 1\n",
    "        else:\n",
    "            predVal = 0\n",
    "        actualVal = testOut[i]\n",
    "        \n",
    "        # Compare actual to predicted values\n",
    "        if (predVal == 1 and predVal == actualVal):\n",
    "            tp += 1\n",
    "        elif (predVal == 1 and predVal != actualVal):\n",
    "            fp += 1\n",
    "        elif (predVal == 0 and predVal == actualVal):\n",
    "            tn += 1\n",
    "        elif (predVal == 0 and predVal != actualVal):\n",
    "            fn += 1\n",
    "        \n",
    "    # Compute and display accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(\"k: {}, Accuracy: {}\".format(k, accuracy))\n",
    "    \n",
    "    # Update highest accuracy and store corresponding confusion matrix\n",
    "    if (accuracy > accuracy_opt):\n",
    "        accuracy_opt = accuracy\n",
    "        k_opt = k\n",
    "        confMatrix_opt[0][0] = tp\n",
    "        confMatrix_opt[0][1] = fp\n",
    "        confMatrix_opt[1][0] = fn\n",
    "        confMatrix_opt[1][1] = tn\n",
    "        \n",
    "# Compute results from optimal values\n",
    "tp = confMatrix_opt[0][0]\n",
    "fp = confMatrix_opt[0][1]\n",
    "fn = confMatrix_opt[1][0]\n",
    "tn = confMatrix_opt[1][1]\n",
    "precision_opt = tp / (tp + fp)\n",
    "recall_opt = tp / (tp + fn)\n",
    "f_measure_opt = (2 * (precision_opt * recall_opt)) / (precision_opt + recall_opt)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nOptimal k value: \", k_opt)\n",
    "print(\"Confusion Matrix: \", confMatrix_opt, \"\\n\")\n",
    "print(\"Accuracy: \", accuracy_opt)\n",
    "print(\"Precision: \", precision_opt)\n",
    "print(\"Recall: \", recall_opt)\n",
    "print(\"F-measure: \", f_measure_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
