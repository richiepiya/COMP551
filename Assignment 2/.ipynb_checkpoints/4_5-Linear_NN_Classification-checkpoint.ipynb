{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-eb347b43c87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Save completed datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataGenerated/DS2_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mtrainSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataGenerated/DS2_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mvalidSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataGenerated/DS2_valid.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataGenerated/DS2_test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Read data from DataSets\n",
    "mean1_pos = pd.read_csv(\"data/DS2_c1_m1.txt\", header=None)\n",
    "mean2_pos = pd.read_csv(\"data/DS2_c1_m2.txt\", header=None)\n",
    "mean3_pos = pd.read_csv(\"data/DS2_c1_m3.txt\", header=None)\n",
    "mean1_neg = pd.read_csv(\"data/DS2_c2_m1.txt\", header=None)\n",
    "mean2_neg = pd.read_csv(\"data/DS2_c2_m2.txt\", header=None)\n",
    "mean3_neg = pd.read_csv(\"data/DS2_c2_m3.txt\", header=None)\n",
    "cov1 = pd.read_csv(\"data/DS2_Cov1.txt\", header=None)\n",
    "cov2 = pd.read_csv(\"data/DS2_Cov2.txt\", header=None)\n",
    "cov3 = pd.read_csv(\"data/DS2_Cov3.txt\", header=None)\n",
    "# Drop end column (not useful to us)\n",
    "mean1_pos.drop([20], axis=1, inplace=True)\n",
    "mean2_pos.drop([20], axis=1, inplace=True)\n",
    "mean3_pos.drop([20], axis=1, inplace=True)\n",
    "mean1_neg.drop([20], axis=1, inplace=True)\n",
    "mean2_neg.drop([20], axis=1, inplace=True)\n",
    "mean3_neg.drop([20], axis=1, inplace=True)\n",
    "cov1.drop([20], axis=1, inplace=True)\n",
    "cov2.drop([20], axis=1, inplace=True)\n",
    "cov3.drop([20], axis=1, inplace=True)\n",
    "# Change to matrices\n",
    "mean1_pos_m = mean1_pos.as_matrix()[0]\n",
    "mean2_pos_m = mean2_pos.as_matrix()[0]\n",
    "mean3_pos_m = mean3_pos.as_matrix()[0]\n",
    "mean1_neg_m = mean1_neg.as_matrix()[0]\n",
    "mean2_neg_m = mean2_neg.as_matrix()[0]\n",
    "mean3_neg_m = mean3_neg.as_matrix()[0]\n",
    "cov1_m = cov1.as_matrix()[0]\n",
    "cov2_m = cov2.as_matrix()[0]\n",
    "cov3_m = cov3.as_matrix()[0]\n",
    "\n",
    "# Generate 2000 examples for each class\n",
    "dataEx = 2000\n",
    "class1_neg = pd.DataFrame(np.random.multivariate_normal(mean1_neg_m, cov1, dataEx))\n",
    "class2_neg = pd.DataFrame(np.random.multivariate_normal(mean2_neg_m, cov2, dataEx))\n",
    "class3_neg = pd.DataFrame(np.random.multivariate_normal(mean3_neg_m, cov3, dataEx))\n",
    "class1_pos = pd.DataFrame(np.random.multivariate_normal(mean1_pos_m, cov1, dataEx))\n",
    "class2_pos = pd.DataFrame(np.random.multivariate_normal(mean2_pos_m, cov2, dataEx))\n",
    "class3_pos = pd.DataFrame(np.random.multivariate_normal(mean3_pos_m, cov3, dataEx))\n",
    "# Add classification column and convert to matrix\n",
    "class1_neg[20] = 0\n",
    "class2_neg[20] = 0\n",
    "class3_neg[20] = 0\n",
    "class1_pos[20] = 1\n",
    "class2_pos[20] = 1\n",
    "class3_pos[20] = 1\n",
    "class1_neg_m = class1_neg.as_matrix()\n",
    "class2_neg_m = class2_neg.as_matrix()\n",
    "class3_neg_m = class3_neg.as_matrix()\n",
    "class1_pos_m = class1_pos.as_matrix()\n",
    "class2_pos_m = class2_pos.as_matrix()\n",
    "class3_pos_m = class3_pos.as_matrix()\n",
    "\n",
    "# Split data into train, valid, test sets\n",
    "allData1 = np.concatenate((class1_neg_m, class1_pos_m), axis=0)\n",
    "allData2 = np.concatenate((class2_neg_m, class2_pos_m), axis=0)\n",
    "allData3 = np.concatenate((class3_neg_m, class3_pos_m), axis=0)\n",
    "np.random.shuffle(allData1)\n",
    "np.random.shuffle(allData2)\n",
    "np.random.shuffle(allData3)\n",
    "trainSet1 = pd.DataFrame(allData1[0:2400])\n",
    "trainSet2 = pd.DataFrame(allData2[0:2400])\n",
    "trainSet3 = pd.DataFrame(allData3[0:2400])\n",
    "validSet1 = pd.DataFrame(allData1[2400:3200])\n",
    "validSet2 = pd.DataFrame(allData2[2400:3200])\n",
    "validSet3 = pd.DataFrame(allData3[2400:3200])\n",
    "testSet1 = pd.DataFrame(allData1[3200:4000])\n",
    "testSet2 = pd.DataFrame(allData2[3200:4000])\n",
    "testSet3 = pd.DataFrame(allData3[3200:4000])\n",
    "# Concatenate data from the 3 Gaussian datasets\n",
    "allData = np.concatenate((pd.DataFrame(allData1), pd.DataFrame(allData2), pd.DataFrame(allData3)), axis=0)\n",
    "trainSet = pd.DataFrame(np.concatenate((trainSet1, trainSet2, trainSet3), axis=0))\n",
    "validSet = pd.DataFrame(np.concatenate((validSet1, validSet2, validSet3), axis=0))\n",
    "testSet = pd.DataFrame(np.concatenate((testSet1, testSet2, testSet3), axis=0))\n",
    "\n",
    "# Save completed datasets\n",
    "pd.DataFrame(allData).to_csv(\"dataGenerated/DS2_data.csv\", index=False, header=False)\n",
    "trainSet.to_csv(\"dataGenerated/DS2_train.csv\", index=False, header=False)\n",
    "validSet.to_csv(\"dataGenerated/DS2_valid.csv\", index=False, header=False)\n",
    "testSet.to_csv(\"dataGenerated/DS2_test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
