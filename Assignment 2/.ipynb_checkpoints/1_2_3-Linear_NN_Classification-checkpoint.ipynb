{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Read data from DataSets\n",
    "mean0 = pd.read_csv(\"data/DS1_m_0.txt\", header=None)\n",
    "mean1 = pd.read_csv(\"data/DS1_m_1.txt\", header=None)\n",
    "cov = pd.read_csv(\"data/DS1_Cov.txt\", header=None)\n",
    "# Drop end column (not useful to us)\n",
    "mean0.drop([20], axis=1, inplace=True)\n",
    "mean1.drop([20], axis=1, inplace=True)\n",
    "cov.drop([20], axis=1, inplace=True)\n",
    "# Change to matrices\n",
    "mean0_m = mean0.as_matrix()[0]\n",
    "mean1_m = mean1.as_matrix()[0]\n",
    "cov_m = cov.as_matrix()[0]\n",
    "\n",
    "# Generate 2000 examples for each class\n",
    "dataEx = 2000\n",
    "class0 = pd.DataFrame(np.random.multivariate_normal(mean0_m, cov, dataEx))\n",
    "class1 = pd.DataFrame(np.random.multivariate_normal(mean1_m, cov, dataEx))\n",
    "# Add classification column and convert to matrix\n",
    "class0[20] = 0\n",
    "class1[20] = 1\n",
    "class0_m = class0.as_matrix()\n",
    "class1_m = class1.as_matrix()\n",
    "\n",
    "# Split data into train, valid, test sets\n",
    "allData = np.concatenate((class0_m, class1_m), axis=0)\n",
    "np.random.shuffle(allData)\n",
    "trainSet = pd.DataFrame(allData[0:2400])\n",
    "validSet = pd.DataFrame(allData[2400:3200])\n",
    "testSet = pd.DataFrame(allData[3200:4000])\n",
    "\n",
    "### 1. Save completed datasets ###\n",
    "pd.DataFrame(allData).to_csv(\"dataGenerated/DS1_data.csv\", index=False, header=False)\n",
    "trainSet.to_csv(\"dataGenerated/DS1_train.csv\", index=False, header=False)\n",
    "validSet.to_csv(\"dataGenerated/DS1_valid.csv\", index=False, header=False)\n",
    "testSet.to_csv(\"dataGenerated/DS1_test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:  [[ 7.56965871  5.35116696  5.95821863  4.81981756  5.47768864  5.95704429\n",
      "   4.37888331  5.15338055  4.80976459  4.95879917  3.71062406  5.01774296\n",
      "   6.81049376  5.65901027  5.9135537   5.71352219  5.66374337  5.43252301\n",
      "   5.34987145  5.66057083]\n",
      " [ 5.35116696  6.89997072  5.36619241  4.23133171  5.28046858  5.60710369\n",
      "   4.22345817  3.90711406  4.08272555  4.94947743  3.18390365  4.57907662\n",
      "   5.78763808  4.93405907  5.47315963  5.25853881  5.65335448  5.0766118\n",
      "   5.23412502  5.17383434]\n",
      " [ 5.95821863  5.36619241  7.35395397  4.70263686  5.60756847  6.63657833\n",
      "   4.50152313  4.66275825  4.89814795  5.04851547  3.13199747  4.59100736\n",
      "   6.26124324  5.02290006  6.1477254   5.98628305  6.25092761  4.88630087\n",
      "   4.55858002  4.985016  ]\n",
      " [ 4.81981756  4.23133171  4.70263686  5.52654937  4.96926381  4.36116252\n",
      "   3.55152567  4.07785514  3.25941865  4.07684604  2.56177122  3.95928561\n",
      "   5.56610168  4.41932067  4.57356955  4.81054172  4.52339249  4.29346492\n",
      "   3.62888363  5.51389486]\n",
      " [ 5.47768864  5.28046858  5.60756847  4.96926381  6.67841143  5.22730161\n",
      "   4.77125945  4.04190715  4.51235063  4.87874017  3.84015512  4.74942353\n",
      "   5.89587741  5.45196203  5.79435001  5.93175572  5.72937352  4.85780389\n",
      "   5.05117753  5.45692   ]\n",
      " [ 5.95704429  5.60710369  6.63657833  4.36116252  5.22730161  6.78776972\n",
      "   4.38647252  4.82425083  4.74936439  5.3383247   2.84677147  4.80343237\n",
      "   6.35555126  4.8600438   5.86942341  6.0374724   5.94607871  4.93251366\n",
      "   4.71608366  5.13682283]\n",
      " [ 4.37888331  4.22345817  4.50152313  3.55152567  4.77125945  4.38647252\n",
      "   4.98008418  3.66987446  3.82916343  4.18532287  2.77638023  4.16453193\n",
      "   4.513068    3.867108    4.5610925   5.05749282  4.19809895  3.47382186\n",
      "   4.38304402  3.75710287]\n",
      " [ 5.15338055  3.90711406  4.66275825  4.07785514  4.04190715  4.82425083\n",
      "   3.66987446  5.76168435  3.45323866  4.82210325  2.35521296  4.65645947\n",
      "   5.92184616  4.9024685   4.70855056  5.92087347  4.37289092  4.72539923\n",
      "   4.60618155  4.28595666]\n",
      " [ 4.80976459  4.08272555  4.89814795  3.25941865  4.51235063  4.74936439\n",
      "   3.82916343  3.45323866  4.93242131  4.53778697  2.99081145  3.98571896\n",
      "   4.9806954   4.47722558  4.92986704  5.13609896  5.10663803  3.95646655\n",
      "   4.07775635  3.96426682]\n",
      " [ 4.95879917  4.94947743  5.04851547  4.07684604  4.87874017  5.3383247\n",
      "   4.18532287  4.82210325  4.53778697  6.97729419  3.06929228  4.61687014\n",
      "   6.66278009  4.9695321   4.8962851   5.91242821  4.69760229  5.15715351\n",
      "   4.33456606  5.16193585]\n",
      " [ 3.71062406  3.18390365  3.13199747  2.56177122  3.84015512  2.84677147\n",
      "   2.77638023  2.35521296  2.99081145  3.06929228  3.15986912  2.71303312\n",
      "   3.4887873   3.6645886   3.45909261  3.49770866  3.4963568   3.00811166\n",
      "   3.4953375   3.24554896]\n",
      " [ 5.01774296  4.57907662  4.59100736  3.95928561  4.74942353  4.80343237\n",
      "   4.16453193  4.65645947  3.98571896  4.61687014  2.71303312  5.10249406\n",
      "   5.81793324  4.75329249  4.74511036  5.4189937   4.95200627  4.71739901\n",
      "   4.82946807  4.36411338]\n",
      " [ 6.81049376  5.78763808  6.26124324  5.56610168  5.89587741  6.35555126\n",
      "   4.513068    5.92184616  4.9806954   6.66278009  3.4887873   5.81793324\n",
      "   8.778226    5.940793    6.09748556  6.38955443  5.88108894  6.10236128\n",
      "   5.61671095  7.02538921]\n",
      " [ 5.65901027  4.93405907  5.02290006  4.41932067  5.45196203  4.8600438\n",
      "   3.867108    4.9024685   4.47722558  4.9695321   3.6645886   4.75329249\n",
      "   5.940793    6.52938893  5.66369625  5.96871172  5.51861888  5.33545624\n",
      "   5.58420367  5.12291285]\n",
      " [ 5.9135537   5.47315963  6.1477254   4.57356955  5.79435001  5.86942341\n",
      "   4.5610925   4.70855056  4.92986704  4.8962851   3.45909261  4.74511036\n",
      "   6.09748556  5.66369625  6.93287794  7.01166305  5.92216599  5.00412858\n",
      "   5.33579171  5.48468623]\n",
      " [ 5.71352219  5.25853881  5.98628305  4.81054172  5.93175572  6.0374724\n",
      "   5.05749282  5.92087347  5.13609896  5.91242821  3.49770866  5.4189937\n",
      "   6.38955443  5.96871172  7.01166305  9.03654145  5.92887705  5.72459572\n",
      "   5.46714189  5.61190014]\n",
      " [ 5.66374337  5.65335448  6.25092761  4.52339249  5.72937352  5.94607871\n",
      "   4.19809895  4.37289092  5.10663803  4.69760229  3.4963568   4.95200627\n",
      "   5.88108894  5.51861888  5.92216599  5.92887705  6.75451736  5.11133301\n",
      "   5.17030759  4.84758453]\n",
      " [ 5.43252301  5.0766118   4.88630087  4.29346492  4.85780389  4.93251366\n",
      "   3.47382186  4.72539923  3.95646655  5.15715351  3.00811166  4.71739901\n",
      "   6.10236128  5.33545624  5.00412858  5.72459572  5.11133301  5.79484751\n",
      "   4.63462952  4.88432996]\n",
      " [ 5.34987145  5.23412502  4.55858002  3.62888363  5.05117753  4.71608366\n",
      "   4.38304402  4.60618155  4.07775635  4.33456606  3.4953375   4.82946807\n",
      "   5.61671095  5.58420367  5.33579171  5.46714189  5.17030759  4.63462952\n",
      "   6.13968085  4.6747043 ]\n",
      " [ 5.66057083  5.17383434  4.985016    5.51389486  5.45692     5.13682283\n",
      "   3.75710287  4.28595666  3.96426682  5.16193585  3.24554896  4.36411338\n",
      "   7.02538921  5.12291285  5.48468623  5.61190014  4.84758453  4.88432996\n",
      "   4.6747043   7.59744548]] \n",
      "\n",
      "w0:  27.0063735387\n",
      "w1:  [ 14.20973873  -8.39842924  -5.83927592  -3.27194781  -9.52374936\n",
      "  -4.13029902  16.79636065 -23.57558641 -28.65705894   8.85520668\n",
      " -12.9757844  -12.10569073  15.52936256  12.90480411  -5.57306485\n",
      "  12.88872263  29.0973488   -6.82594044  -0.86265384  -4.88902291] \n",
      "\n",
      "Confusion Matrix:  [[382, 19], [21, 378]] \n",
      "\n",
      "Accuracy:  0.95\n",
      "Precision:  0.9526184538653366\n",
      "Recall:  0.9478908188585607\n",
      "F-measure:  0.9502487562189055\n"
     ]
    }
   ],
   "source": [
    "### 2. GDA Approach ###\n",
    "\n",
    "# Split training data\n",
    "trainSet0 = trainSet[trainSet[20] == 0]\n",
    "trainSet1 = trainSet[trainSet[20] == 1]\n",
    "testOut = testSet[20]\n",
    "# Drop end column\n",
    "trainSet0.drop([20], axis=1, inplace=True)\n",
    "trainSet1.drop([20], axis=1, inplace=True)\n",
    "trainSet.drop([20], axis=1, inplace=True)\n",
    "testSet.drop([20], axis=1, inplace=True)\n",
    "\n",
    "# Get length of each training set\n",
    "numData0 = len(trainSet0)\n",
    "numData1 = len(trainSet1)\n",
    "# Create nd.array versions of data sets\n",
    "trainSet_arr = trainSet.as_matrix()\n",
    "testSet_arr = testSet.as_matrix()\n",
    "\n",
    "# Get probability of each training set\n",
    "allDataPts = numData0 + numData1\n",
    "prob0 = numData0 / allDataPts\n",
    "prob1 = numData1 / allDataPts\n",
    "\n",
    "# Get mean of each column\n",
    "mean0 = np.array(trainSet0.mean())\n",
    "mean1 = np.array(trainSet1.mean())\n",
    "\n",
    "# Compute covariance matrices to get w0 & w1\n",
    "cov0 = np.array(trainSet0-mean0)\n",
    "cov1 = np.array(trainSet1-mean1)\n",
    "s0 = np.matmul(cov0.T, cov0)\n",
    "s1 = np.matmul(cov1.T, cov1)\n",
    "cov = (s0 + s1) / allDataPts\n",
    "cov_inv = np.linalg.inv(cov)\n",
    "w0 = (math.log(prob0)-math.log(prob1)) - (np.matmul(np.matmul(mean0.T, cov_inv), mean0) - np.matmul(np.matmul(mean1.T, cov_inv), mean1))/2\n",
    "w1 = np.matmul(cov_inv, (mean0 - mean1))\n",
    "print(\"Covariance matrix: \", cov, \"\\n\")\n",
    "print(\"w0: \", w0)\n",
    "print(\"w1: \", w1, \"\\n\")\n",
    "\n",
    "# Compute GDA model\n",
    "outPredict = np.matmul(testSet, w1.T) + w0\n",
    "sigmoid = np.exp(outPredict) / (np.exp(outPredict) + 1)\n",
    "for i in range(len(sigmoid)):\n",
    "    if (sigmoid[i] > 0.5):\n",
    "        sigmoid[i] = 0\n",
    "    else:\n",
    "        sigmoid[i] = 1\n",
    "        \n",
    "# Compute confusion matrix values\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for j in range(len(testOut)):\n",
    "    predVal = sigmoid[j]\n",
    "    actualVal = testOut[j]\n",
    "\n",
    "    # Compare actual to predicted values\n",
    "    if (predVal == 1 and predVal == actualVal):\n",
    "        tp += 1\n",
    "    elif (predVal == 1 and predVal != actualVal):\n",
    "        fp += 1\n",
    "    elif (predVal == 0 and predVal == actualVal):\n",
    "        tn += 1\n",
    "    elif (predVal == 0 and predVal != actualVal):\n",
    "        fn += 1\n",
    "        \n",
    "# Create confusion matrix\n",
    "confMatrix = [[0, 0], [0, 0]]\n",
    "confMatrix[0][0] = tp\n",
    "confMatrix[0][1] = fp\n",
    "confMatrix[1][0] = fn\n",
    "confMatrix[1][1] = tn\n",
    "        \n",
    "# Compute results\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f_measure = (2 * (precision * recall)) / (precision + recall)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix: \", confMatrix, \"\\n\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F-measure: \", f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Accuracy: 0.535\n",
      "k: 2, Accuracy: 0.52625\n",
      "k: 3, Accuracy: 0.52625\n",
      "k: 4, Accuracy: 0.53375\n",
      "k: 5, Accuracy: 0.535\n",
      "k: 6, Accuracy: 0.54125\n",
      "k: 7, Accuracy: 0.54\n",
      "k: 8, Accuracy: 0.54375\n",
      "k: 9, Accuracy: 0.54375\n",
      "k: 10, Accuracy: 0.54375\n",
      "k: 11, Accuracy: 0.54125\n",
      "k: 12, Accuracy: 0.54\n",
      "k: 13, Accuracy: 0.53875\n",
      "k: 14, Accuracy: 0.54\n",
      "k: 15, Accuracy: 0.54\n",
      "k: 16, Accuracy: 0.54\n",
      "k: 17, Accuracy: 0.5425\n",
      "k: 18, Accuracy: 0.5425\n",
      "k: 19, Accuracy: 0.54\n",
      "k: 20, Accuracy: 0.53875\n",
      "k: 21, Accuracy: 0.5375\n",
      "k: 22, Accuracy: 0.535\n",
      "k: 23, Accuracy: 0.53625\n",
      "k: 24, Accuracy: 0.535\n",
      "k: 25, Accuracy: 0.535\n",
      "k: 26, Accuracy: 0.53625\n",
      "k: 27, Accuracy: 0.54125\n",
      "k: 28, Accuracy: 0.535\n",
      "k: 29, Accuracy: 0.53625\n",
      "k: 30, Accuracy: 0.5375\n",
      "\n",
      "Optimal k value:  8\n",
      "Confusion Matrix:  [[314, 276], [89, 121]] \n",
      "\n",
      "Accuracy:  0.54375\n",
      "Precision:  0.5322033898305085\n",
      "Recall:  0.7791563275434243\n",
      "F-measure:  0.6324269889224572\n"
     ]
    }
   ],
   "source": [
    "### 3. k-NN Approach ###\n",
    "\n",
    "# Store optimal values\n",
    "k_opt = 0\n",
    "confMatrix_opt = [[0, 0], [0, 0]]\n",
    "accuracy_opt = 0.0\n",
    "\n",
    "# Compute k-NN up to k=30\n",
    "for k in range(1, 31):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(testOut)):\n",
    "        x = trainSet_arr\n",
    "        y_i = testSet_arr[i]\n",
    "        \n",
    "        # Compute and sort distances\n",
    "        distances = np.power(np.linalg.norm(x - y_i, axis=1), 2)\n",
    "        neighbours = distances.argsort()[:k]\n",
    "        if (trainSet_arr[neighbours, 19].sum() > 0):\n",
    "            predVal = 1\n",
    "        else:\n",
    "            predVal = 0\n",
    "        actualVal = testOut[i]\n",
    "        \n",
    "        # Compare actual to predicted values\n",
    "        if (predVal == 1 and predVal == actualVal):\n",
    "            tp += 1\n",
    "        elif (predVal == 1 and predVal != actualVal):\n",
    "            fp += 1\n",
    "        elif (predVal == 0 and predVal == actualVal):\n",
    "            tn += 1\n",
    "        elif (predVal == 0 and predVal != actualVal):\n",
    "            fn += 1\n",
    "        \n",
    "    # Compute and display accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(\"k: {}, Accuracy: {}\".format(k, accuracy))\n",
    "    \n",
    "    # Update highest accuracy and store corresponding confusion matrix\n",
    "    if (accuracy > accuracy_opt):\n",
    "        accuracy_opt = accuracy\n",
    "        k_opt = k\n",
    "        confMatrix_opt[0][0] = tp\n",
    "        confMatrix_opt[0][1] = fp\n",
    "        confMatrix_opt[1][0] = fn\n",
    "        confMatrix_opt[1][1] = tn\n",
    "        \n",
    "# Compute results from optimal values\n",
    "tp = confMatrix_opt[0][0]\n",
    "fp = confMatrix_opt[0][1]\n",
    "fn = confMatrix_opt[1][0]\n",
    "tn = confMatrix_opt[1][1]\n",
    "precision_opt = tp / (tp + fp)\n",
    "recall_opt = tp / (tp + fn)\n",
    "f_measure_opt = (2 * (precision_opt * recall_opt)) / (precision_opt + recall_opt)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nOptimal k value: \", k_opt)\n",
    "print(\"Confusion Matrix: \", confMatrix_opt, \"\\n\")\n",
    "print(\"Accuracy: \", accuracy_opt)\n",
    "print(\"Precision: \", precision_opt)\n",
    "print(\"Recall: \", recall_opt)\n",
    "print(\"F-measure: \", f_measure_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
