{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Read data from DataSets\n",
    "mean1_pos = pd.read_csv(\"data/DS2_c1_m1.txt\", header=None)\n",
    "mean2_pos = pd.read_csv(\"data/DS2_c1_m2.txt\", header=None)\n",
    "mean3_pos = pd.read_csv(\"data/DS2_c1_m3.txt\", header=None)\n",
    "mean1_neg = pd.read_csv(\"data/DS2_c2_m1.txt\", header=None)\n",
    "mean2_neg = pd.read_csv(\"data/DS2_c2_m2.txt\", header=None)\n",
    "mean3_neg = pd.read_csv(\"data/DS2_c2_m3.txt\", header=None)\n",
    "cov1 = pd.read_csv(\"data/DS2_Cov1.txt\", header=None)\n",
    "cov2 = pd.read_csv(\"data/DS2_Cov2.txt\", header=None)\n",
    "cov3 = pd.read_csv(\"data/DS2_Cov3.txt\", header=None)\n",
    "# Drop end column (not useful to us)\n",
    "mean1_pos.drop([20], axis=1, inplace=True)\n",
    "mean2_pos.drop([20], axis=1, inplace=True)\n",
    "mean3_pos.drop([20], axis=1, inplace=True)\n",
    "mean1_neg.drop([20], axis=1, inplace=True)\n",
    "mean2_neg.drop([20], axis=1, inplace=True)\n",
    "mean3_neg.drop([20], axis=1, inplace=True)\n",
    "cov1.drop([20], axis=1, inplace=True)\n",
    "cov2.drop([20], axis=1, inplace=True)\n",
    "cov3.drop([20], axis=1, inplace=True)\n",
    "# Change to matrices\n",
    "mean1_pos_m = mean1_pos.as_matrix()[0]\n",
    "mean2_pos_m = mean2_pos.as_matrix()[0]\n",
    "mean3_pos_m = mean3_pos.as_matrix()[0]\n",
    "mean1_neg_m = mean1_neg.as_matrix()[0]\n",
    "mean2_neg_m = mean2_neg.as_matrix()[0]\n",
    "mean3_neg_m = mean3_neg.as_matrix()[0]\n",
    "cov1_m = cov1.as_matrix()[0]\n",
    "cov2_m = cov2.as_matrix()[0]\n",
    "cov3_m = cov3.as_matrix()[0]\n",
    "\n",
    "# Generate 2000 examples for each class\n",
    "dataEx = 2000\n",
    "class1_neg = pd.DataFrame(np.random.multivariate_normal(mean1_neg_m, cov1, dataEx))\n",
    "class2_neg = pd.DataFrame(np.random.multivariate_normal(mean2_neg_m, cov2, dataEx))\n",
    "class3_neg = pd.DataFrame(np.random.multivariate_normal(mean3_neg_m, cov3, dataEx))\n",
    "class1_pos = pd.DataFrame(np.random.multivariate_normal(mean1_pos_m, cov1, dataEx))\n",
    "class2_pos = pd.DataFrame(np.random.multivariate_normal(mean2_pos_m, cov2, dataEx))\n",
    "class3_pos = pd.DataFrame(np.random.multivariate_normal(mean3_pos_m, cov3, dataEx))\n",
    "# Add classification column and convert to matrix\n",
    "class1_neg[20] = 0\n",
    "class2_neg[20] = 0\n",
    "class3_neg[20] = 0\n",
    "class1_pos[20] = 1\n",
    "class2_pos[20] = 1\n",
    "class3_pos[20] = 1\n",
    "class1_neg_m = class1_neg.as_matrix()\n",
    "class2_neg_m = class2_neg.as_matrix()\n",
    "class3_neg_m = class3_neg.as_matrix()\n",
    "class1_pos_m = class1_pos.as_matrix()\n",
    "class2_pos_m = class2_pos.as_matrix()\n",
    "class3_pos_m = class3_pos.as_matrix()\n",
    "\n",
    "# Split data into train, valid, test sets\n",
    "allData1 = np.concatenate((class1_neg_m, class1_pos_m), axis=0)\n",
    "allData2 = np.concatenate((class2_neg_m, class2_pos_m), axis=0)\n",
    "allData3 = np.concatenate((class3_neg_m, class3_pos_m), axis=0)\n",
    "np.random.shuffle(allData1)\n",
    "np.random.shuffle(allData2)\n",
    "np.random.shuffle(allData3)\n",
    "trainSet1 = pd.DataFrame(allData1[0:2400])\n",
    "trainSet2 = pd.DataFrame(allData2[0:2400])\n",
    "trainSet3 = pd.DataFrame(allData3[0:2400])\n",
    "validSet1 = pd.DataFrame(allData1[2400:3200])\n",
    "validSet2 = pd.DataFrame(allData2[2400:3200])\n",
    "validSet3 = pd.DataFrame(allData3[2400:3200])\n",
    "testSet1 = pd.DataFrame(allData1[3200:4000])\n",
    "testSet2 = pd.DataFrame(allData2[3200:4000])\n",
    "testSet3 = pd.DataFrame(allData3[3200:4000])\n",
    "# Concatenate data from the 3 Gaussian datasets\n",
    "allData = np.concatenate((pd.DataFrame(allData1), pd.DataFrame(allData2), pd.DataFrame(allData3)), axis=0)\n",
    "trainSet = pd.DataFrame(np.concatenate((trainSet1, trainSet2, trainSet3), axis=0))\n",
    "validSet = pd.DataFrame(np.concatenate((validSet1, validSet2, validSet3), axis=0))\n",
    "testSet = pd.DataFrame(np.concatenate((testSet1, testSet2, testSet3), axis=0))\n",
    "\n",
    "# Save completed datasets\n",
    "pd.DataFrame(allData).to_csv(\"dataGenerated/DS2_data.csv\", index=False, header=False)\n",
    "trainSet.to_csv(\"dataGenerated/DS2_train.csv\", index=False, header=False)\n",
    "validSet.to_csv(\"dataGenerated/DS2_valid.csv\", index=False, header=False)\n",
    "testSet.to_csv(\"dataGenerated/DS2_test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:  [[ 7.50122388  5.57884754  4.95056876  5.0348809   4.39033786  6.05880853\n",
      "   5.5345607   5.29956532  4.72478605  5.42966928  5.30664251  5.26026878\n",
      "   5.3794607   6.12062415  5.35040496  5.78854079  5.47401514  5.20974579\n",
      "   5.16666827  5.69803602]\n",
      " [ 5.57884754  7.52287489  5.31441971  5.3159981   5.17228527  6.53063054\n",
      "   6.24403652  5.54008758  4.92958021  5.44818885  5.11266988  5.5948526\n",
      "   5.30541587  6.18758946  5.78626593  6.11887465  5.68396922  5.17450143\n",
      "   5.77658978  5.9880496 ]\n",
      " [ 4.95056876  5.31441971  6.79319325  5.05209305  4.85460698  5.47044114\n",
      "   5.64954053  4.56577658  4.8072797   5.04832627  4.82390034  5.13027899\n",
      "   5.3220334   6.03045462  5.07527386  5.06914785  5.46037641  4.44966546\n",
      "   5.33842861  5.83273468]\n",
      " [ 5.0348809   5.3159981   5.05209305  6.40422881  4.15124126  5.65968514\n",
      "   5.52861617  5.25959995  4.70467988  5.41220914  4.7432687   5.19971191\n",
      "   4.93759861  5.33761305  5.24025098  5.22980256  5.17078493  4.974746\n",
      "   5.29678964  5.60195217]\n",
      " [ 4.39033786  5.17228527  4.85460698  4.15124126  5.66740516  5.04374429\n",
      "   4.77852826  4.51026286  3.77607521  4.215814    3.77750775  4.2507421\n",
      "   4.51658162  4.90954779  4.9913274   4.94585359  4.74120311  4.5124835\n",
      "   4.78935343  5.11582726]\n",
      " [ 6.05880853  6.53063054  5.47044114  5.65968514  5.04374429  8.49691696\n",
      "   6.5942961   5.45102985  5.78494958  6.02466717  5.16537697  5.74680748\n",
      "   6.22782457  6.68524379  5.96608304  6.41880048  6.03444465  5.86692175\n",
      "   6.35445726  6.52260582]\n",
      " [ 5.5345607   6.24403652  5.64954053  5.52861617  4.77852826  6.5942961\n",
      "   7.54916604  5.5908068   5.32264724  5.90458532  5.44468562  5.5790084\n",
      "   5.48876716  6.3930727   5.63566756  5.94891234  5.57314127  5.34579762\n",
      "   6.126764    6.07805057]\n",
      " [ 5.29956532  5.54008758  4.56577658  5.25959995  4.51026286  5.45102985\n",
      "   5.5908068   6.30135505  4.5189345   5.21199747  4.55678152  5.02429327\n",
      "   4.47920987  5.35940024  5.33881016  5.30675518  5.02446785  5.40873871\n",
      "   5.07351584  5.56443425]\n",
      " [ 4.72478605  4.92958021  4.8072797   4.70467988  3.77607521  5.78494958\n",
      "   5.32264724  4.5189345   5.96210376  4.68812279  4.38640137  4.5922715\n",
      "   4.66914147  4.89063405  4.67342628  4.46866767  4.79660865  4.42522701\n",
      "   4.7095988   4.99894528]\n",
      " [ 5.42966928  5.44818885  5.04832627  5.41220914  4.215814    6.02466717\n",
      "   5.90458532  5.21199747  4.68812279  6.87574032  4.8424087   5.06596552\n",
      "   5.23110844  5.79968525  5.34092759  5.28119556  5.15411171  4.73579447\n",
      "   5.62265137  5.55215114]\n",
      " [ 5.30664251  5.11266988  4.82390034  4.7432687   3.77750775  5.16537697\n",
      "   5.44468562  4.55678152  4.38640137  4.8424087   5.95783338  5.14208942\n",
      "   4.87365028  5.19892887  5.02717117  4.79574985  4.71161313  4.59823757\n",
      "   5.13061821  5.27826372]\n",
      " [ 5.26026878  5.5948526   5.13027899  5.19971191  4.2507421   5.74680748\n",
      "   5.5790084   5.02429327  4.5922715   5.06596552  5.14208942  6.91452116\n",
      "   5.00749923  5.55505655  5.69328985  5.35959234  5.5362752   5.23284043\n",
      "   5.2650679   5.73358065]\n",
      " [ 5.3794607   5.30541587  5.3220334   4.93759861  4.51658162  6.22782457\n",
      "   5.48876716  4.47920987  4.66914147  5.23110844  4.87365028  5.00749923\n",
      "   6.81256693  5.77881404  5.67627508  5.63708354  5.43216189  4.88822995\n",
      "   5.52451066  5.58613002]\n",
      " [ 6.12062415  6.18758946  6.03045462  5.33761305  4.90954779  6.68524379\n",
      "   6.3930727   5.35940024  4.89063405  5.79968525  5.19892887  5.55505655\n",
      "   5.77881404  7.95955028  5.72718985  6.00567276  6.04506609  4.91041463\n",
      "   5.82180152  6.21186073]\n",
      " [ 5.35040496  5.78626593  5.07527386  5.24025098  4.9913274   5.96608304\n",
      "   5.63566756  5.33881016  4.67342628  5.34092759  5.02717117  5.69328985\n",
      "   5.67627508  5.72718985  7.15337167  5.47857781  5.53998921  5.25273158\n",
      "   5.32677415  6.14440683]\n",
      " [ 5.78854079  6.11887465  5.06914785  5.22980256  4.94585359  6.41880048\n",
      "   5.94891234  5.30675518  4.46866767  5.28119556  4.79574985  5.35959234\n",
      "   5.63708354  6.00567276  5.47857781  6.92878798  5.50702666  5.62698995\n",
      "   5.73226995  5.76554461]\n",
      " [ 5.47401514  5.68396922  5.46037641  5.17078493  4.74120311  6.03444465\n",
      "   5.57314127  5.02446785  4.79660865  5.15411171  4.71161313  5.5362752\n",
      "   5.43216189  6.04506609  5.53998921  5.50702666  7.06203104  4.7846809\n",
      "   5.33810197  6.09037014]\n",
      " [ 5.20974579  5.17450143  4.44966546  4.974746    4.5124835   5.86692175\n",
      "   5.34579762  5.40873871  4.42522701  4.73579447  4.59823757  5.23284043\n",
      "   4.88822995  4.91041463  5.25273158  5.62698995  4.7846809   6.71879378\n",
      "   5.25068122  5.52821243]\n",
      " [ 5.16666827  5.77658978  5.33842861  5.29678964  4.78935343  6.35445726\n",
      "   6.126764    5.07351584  4.7095988   5.62265137  5.13061821  5.2650679\n",
      "   5.52451066  5.82180152  5.32677415  5.73226995  5.33810197  5.25068122\n",
      "   7.24356418  5.88374314]\n",
      " [ 5.69803602  5.9880496   5.83273468  5.60195217  5.11582726  6.52260582\n",
      "   6.07805057  5.56443425  4.99894528  5.55215114  5.27826372  5.73358065\n",
      "   5.58613002  6.21186073  6.14440683  5.76554461  6.09037014  5.52821243\n",
      "   5.88374314  7.91723873]] \n",
      "\n",
      "w0:  -0.110864883937\n",
      "w1:  [-0.03156888 -0.05560138 -0.02836177  0.03024876  0.08366375 -0.0047761\n",
      " -0.0073015   0.00461376  0.0448704   0.03316844  0.06511816  0.0052726\n",
      "  0.01329656  0.01831595 -0.04217873 -0.00394251 -0.00110022  0.00464041\n",
      " -0.02383005 -0.01053945] \n",
      "\n",
      "Confusion Matrix:  [[632, 568], [562, 638]] \n",
      "\n",
      "Accuracy:  0.5291666666666667\n",
      "Precision:  0.5266666666666666\n",
      "Recall:  0.5293132328308208\n",
      "F-measure:  0.5279866332497911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Split training data\n",
    "trainSet0 = trainSet[trainSet[20] == 0]\n",
    "trainSet1 = trainSet[trainSet[20] == 1]\n",
    "testOut = testSet[20]\n",
    "# Drop end column\n",
    "trainSet0.drop([20], axis=1, inplace=True)\n",
    "trainSet1.drop([20], axis=1, inplace=True)\n",
    "trainSet.drop([20], axis=1, inplace=True)\n",
    "testSet.drop([20], axis=1, inplace=True)\n",
    "\n",
    "# Get length of each training set\n",
    "numData0 = len(trainSet0)\n",
    "numData1 = len(trainSet1)\n",
    "# Create nd.array versions of data sets\n",
    "trainSet_arr = trainSet.as_matrix()\n",
    "testSet_arr = testSet.as_matrix()\n",
    "\n",
    "# Get probability of each training set\n",
    "allDataPts = numData0 + numData1\n",
    "prob0 = numData0 / allDataPts\n",
    "prob1 = numData1 / allDataPts\n",
    "\n",
    "# Get mean of each column\n",
    "mean0 = np.array(trainSet0.mean())\n",
    "mean1 = np.array(trainSet1.mean())\n",
    "\n",
    "# Compute covariance matrices to get w0 & w1\n",
    "cov0 = np.array(trainSet0-mean0)\n",
    "cov1 = np.array(trainSet1-mean1)\n",
    "s0 = np.matmul(cov0.T, cov0)\n",
    "s1 = np.matmul(cov1.T, cov1)\n",
    "cov = (s0 + s1) / allDataPts\n",
    "cov_inv = np.linalg.inv(cov)\n",
    "w0 = (math.log(prob0)-math.log(prob1)) - (np.matmul(np.matmul(mean0.T, cov_inv), mean0) - np.matmul(np.matmul(mean1.T, cov_inv), mean1))/2\n",
    "w1 = np.matmul(cov_inv, (mean0 - mean1))\n",
    "print(\"Covariance matrix: \", cov, \"\\n\")\n",
    "print(\"w0: \", w0)\n",
    "print(\"w1: \", w1, \"\\n\")\n",
    "\n",
    "# Compute GDA model\n",
    "outPredict = np.matmul(testSet, w1.T) + w0\n",
    "sigmoid = np.exp(outPredict) / (np.exp(outPredict) + 1)\n",
    "for i in range(len(sigmoid)):\n",
    "    if (sigmoid[i] > 0.5):\n",
    "        sigmoid[i] = 0\n",
    "    else:\n",
    "        sigmoid[i] = 1\n",
    "        \n",
    "# Compute confusion matrix values\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for j in range(len(testOut)):\n",
    "    predVal = sigmoid[j]\n",
    "    actualVal = testOut[j]\n",
    "\n",
    "    # Compare actual to predicted values\n",
    "    if (predVal == 1 and predVal == actualVal):\n",
    "        tp += 1\n",
    "    elif (predVal == 1 and predVal != actualVal):\n",
    "        fp += 1\n",
    "    elif (predVal == 0 and predVal == actualVal):\n",
    "        tn += 1\n",
    "    elif (predVal == 0 and predVal != actualVal):\n",
    "        fn += 1\n",
    "        \n",
    "# Create confusion matrix\n",
    "confMatrix = [[0, 0], [0, 0]]\n",
    "confMatrix[0][0] = tp\n",
    "confMatrix[0][1] = fp\n",
    "confMatrix[1][0] = fn\n",
    "confMatrix[1][1] = tn\n",
    "        \n",
    "# Compute results\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f_measure = (2 * (precision * recall)) / (precision + recall)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix: \", confMatrix, \"\\n\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F-measure: \", f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Accuracy: 0.46625\n",
      "k: 2, Accuracy: 0.47\n",
      "k: 3, Accuracy: 0.46458333333333335\n",
      "k: 4, Accuracy: 0.4683333333333333\n",
      "k: 5, Accuracy: 0.4608333333333333\n",
      "k: 6, Accuracy: 0.4633333333333333\n",
      "k: 7, Accuracy: 0.46416666666666667\n",
      "k: 8, Accuracy: 0.4625\n",
      "k: 9, Accuracy: 0.4658333333333333\n",
      "k: 10, Accuracy: 0.46291666666666664\n",
      "k: 11, Accuracy: 0.465\n",
      "k: 12, Accuracy: 0.4633333333333333\n",
      "k: 13, Accuracy: 0.46375\n",
      "k: 14, Accuracy: 0.46416666666666667\n",
      "k: 15, Accuracy: 0.46291666666666664\n",
      "k: 16, Accuracy: 0.45958333333333334\n",
      "k: 17, Accuracy: 0.46041666666666664\n",
      "k: 18, Accuracy: 0.46041666666666664\n",
      "k: 19, Accuracy: 0.4608333333333333\n",
      "k: 20, Accuracy: 0.46125\n",
      "k: 21, Accuracy: 0.4625\n",
      "k: 22, Accuracy: 0.4633333333333333\n",
      "k: 23, Accuracy: 0.46166666666666667\n",
      "k: 24, Accuracy: 0.4633333333333333\n",
      "k: 25, Accuracy: 0.46291666666666664\n",
      "k: 26, Accuracy: 0.46375\n",
      "k: 27, Accuracy: 0.46375\n",
      "k: 28, Accuracy: 0.4608333333333333\n",
      "k: 29, Accuracy: 0.46208333333333335\n",
      "k: 30, Accuracy: 0.46458333333333335\n",
      "\n",
      "Optimal k value:  2\n",
      "Confusion Matrix:  [[775, 853], [419, 353]] \n",
      "\n",
      "Accuracy:  0.47\n",
      "Precision:  0.476044226044226\n",
      "Recall:  0.6490787269681743\n",
      "F-measure:  0.5492558469170801\n"
     ]
    }
   ],
   "source": [
    "# Store optimal values\n",
    "k_opt = 0\n",
    "confMatrix_opt = [[0, 0], [0, 0]]\n",
    "accuracy_opt = 0.0\n",
    "\n",
    "# Compute k-NN up to k=30\n",
    "for k in range(1, 31):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(testOut)):\n",
    "        x = trainSet_arr\n",
    "        y_i = testSet_arr[i]\n",
    "        \n",
    "        # Compute and sort distances\n",
    "        distances = np.power(np.linalg.norm(x - y_i, axis=1), 2)\n",
    "        neighbours = distances.argsort()[:k]\n",
    "        if (trainSet_arr[neighbours, 19].sum() > 0):\n",
    "            predVal = 1\n",
    "        else:\n",
    "            predVal = 0\n",
    "        actualVal = testOut[i]\n",
    "        \n",
    "        # Compare actual to predicted values\n",
    "        if (predVal == 1 and predVal == actualVal):\n",
    "            tp += 1\n",
    "        elif (predVal == 1 and predVal != actualVal):\n",
    "            fp += 1\n",
    "        elif (predVal == 0 and predVal == actualVal):\n",
    "            tn += 1\n",
    "        elif (predVal == 0 and predVal != actualVal):\n",
    "            fn += 1\n",
    "        \n",
    "    # Compute and display accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(\"k: {}, Accuracy: {}\".format(k, accuracy))\n",
    "    \n",
    "    # Update highest accuracy and store corresponding confusion matrix\n",
    "    if (accuracy > accuracy_opt):\n",
    "        accuracy_opt = accuracy\n",
    "        k_opt = k\n",
    "        confMatrix_opt[0][0] = tp\n",
    "        confMatrix_opt[0][1] = fp\n",
    "        confMatrix_opt[1][0] = fn\n",
    "        confMatrix_opt[1][1] = tn\n",
    "        \n",
    "# Compute results from optimal values\n",
    "tp = confMatrix_opt[0][0]\n",
    "fp = confMatrix_opt[0][1]\n",
    "fn = confMatrix_opt[1][0]\n",
    "tn = confMatrix_opt[1][1]\n",
    "precision_opt = tp / (tp + fp)\n",
    "recall_opt = tp / (tp + fn)\n",
    "f_measure_opt = (2 * (precision_opt * recall_opt)) / (precision_opt + recall_opt)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nOptimal k value: \", k_opt)\n",
    "print(\"Confusion Matrix: \", confMatrix_opt, \"\\n\")\n",
    "print(\"Accuracy: \", accuracy_opt)\n",
    "print(\"Precision: \", precision_opt)\n",
    "print(\"Recall: \", recall_opt)\n",
    "print(\"F-measure: \", f_measure_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
